{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (25, 3)\n",
      "t_data.shape =  (25, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "loaded_data = np.loadtxt('datasets/data-01.csv', delimiter=',')\n",
    "\n",
    "x_data = loaded_data[ :, 0:-1]\n",
    "t_data = loaded_data[ :, [-1]] #마지막 열만 가져옴. \n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([3, 1]))  # 가중치 노드 #normal : 표준 정규화, \n",
    "b = tf.Variable(tf.random_normal([1]))     # 바이어스 노드\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 3])  # None 은 총 데이터 갯수\n",
    "T = tf.placeholder(tf.float32, [None, 1])  # 정답데이터 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.matmul(X, W) + b  # 현재 X, W, b, 를 바탕으로 계산된 값\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y - T))  # MSE 손실함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-5    # 학습율 0.0001\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  0 , loss_val =  91944.97\n",
      "step =  400 , loss_val =  55.553787\n",
      "step =  800 , loss_val =  41.133213\n",
      "step =  1200 , loss_val =  30.949202\n",
      "step =  1600 , loss_val =  23.748028\n",
      "step =  2000 , loss_val =  18.648811\n",
      "step =  2400 , loss_val =  15.032046\n",
      "step =  2800 , loss_val =  12.462018\n",
      "step =  3200 , loss_val =  10.631852\n",
      "step =  3600 , loss_val =  9.325413\n",
      "step =  4000 , loss_val =  8.390309\n",
      "step =  4400 , loss_val =  7.7189918\n",
      "step =  4800 , loss_val =  7.2353973\n",
      "step =  5200 , loss_val =  6.8857436\n",
      "step =  5600 , loss_val =  6.631876\n",
      "step =  6000 , loss_val =  6.446744\n",
      "step =  6400 , loss_val =  6.3110747\n",
      "step =  6800 , loss_val =  6.2111516\n",
      "step =  7200 , loss_val =  6.1371465\n",
      "step =  7600 , loss_val =  6.0820217\n",
      "step =  8000 , loss_val =  6.040699\n",
      "\n",
      "Prediction is  [[180.34618]]\n"
     ]
    }
   ],
   "source": [
    "with  tf.Session()  as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())  # 변수 노드(tf.Variable) 초기화\n",
    "\n",
    "    for step in range(8001):\n",
    "      \n",
    "        loss_val, y_val, _ = sess.run([loss, y, train], feed_dict={X: x_data, T: t_data})    \n",
    "        \n",
    "        \n",
    "        if step % 400 == 0:\n",
    "            print(\"step = \", step, \", loss_val = \", loss_val) # 400번중 한 번만 결과 보겠다. 프린트해라.             \n",
    "    \n",
    "    print(\"\\nPrediction is \", sess.run(y, feed_dict={X: [ [100, 98, 81] ]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
