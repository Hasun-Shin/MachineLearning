{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "# SibSp　-> one hot enconding\n",
    "# One hot encoding SibSp\n",
    "############################################################\n",
    "def get_dummies_sibSp(df_all, df, df_test) :\n",
    "\n",
    "    categories = set(df_all['SibSp'].unique())\n",
    "    df['SibSp'] = pandas.Categorical(df['SibSp'], categories=categories)\n",
    "    df_test['SibSp'] = pandas.Categorical(df_test['SibSp'], categories=categories)\n",
    "\n",
    "    df = pandas.get_dummies(df, columns=['SibSp'])\n",
    "    df_test = pandas.get_dummies(df_test, columns=['SibSp'])\n",
    "\n",
    "    return df, df_test\n",
    "\n",
    "############################################################\n",
    "# Parch　-> one hot enconding\n",
    "# One hot encoding SibSp\n",
    "############################################################\n",
    "def get_dummies_parch(df_all, df, df_test) :\n",
    "\n",
    "    categories = set(df_all['Parch'].unique())\n",
    "    df['Parch'] = pandas.Categorical(df['Parch'], categories=categories)\n",
    "    df_test['Parch'] = pandas.Categorical(df_test['Parch'], categories=categories)\n",
    "\n",
    "    df = pandas.get_dummies(df, columns=['Parch'])\n",
    "    df_test = pandas.get_dummies(df_test, columns=['Parch'])\n",
    "\n",
    "    return df, df_test\n",
    "\n",
    "############################################################\n",
    "# Ticket　-> one hot enconding\n",
    "# One hot encoding Ticket\n",
    "############################################################\n",
    "def get_dummies_ticket(df_all, df, df_test) :\n",
    "\n",
    "    ticket_values = df_all['Ticket'].value_counts()\n",
    "    ticket_values = ticket_values[ticket_values > 1]\n",
    "    ticket_values = pandas.Series(ticket_values.index, name='Ticket')\n",
    "    categories = set(ticket_values.tolist())\n",
    "    df['Ticket'] = pandas.Categorical(df['Ticket'], categories=categories)\n",
    "    df_test['Ticket'] = pandas.Categorical(df_test['Ticket'], categories=categories)\n",
    "\n",
    "    df = pandas.get_dummies(df, columns=['Ticket'])\n",
    "    df_test = pandas.get_dummies(df_test, columns=['Ticket'])\n",
    "\n",
    "    return df, df_test\n",
    "\n",
    "############################################################\n",
    "# Standardization\n",
    "############################################################\n",
    "def standardization(df, df_test) :\n",
    "\n",
    "    standard = StandardScaler()\n",
    "    df_std = pandas.DataFrame(standard.fit_transform(df[['Pclass', 'Fare']].values), columns=['Pclass', 'Fare'])\n",
    "    df.loc[:,'Pclass'] = df_std['Pclass']\n",
    "    df.loc[:,'Fare'] = df_std['Fare']\n",
    "\n",
    "    df_test_std = pandas.DataFrame(standard.transform(df_test[['Pclass', 'Fare']].values), columns=['Pclass', 'Fare'])\n",
    "    df_test.loc[:,'Pclass'] = df_test_std['Pclass']\n",
    "    df_test.loc[:,'Fare'] = df_test_std['Fare']\n",
    "\n",
    "    return df, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "############################################################\n",
    "# prepare Data\n",
    "############################################################\n",
    "def prepareData() :\n",
    "\n",
    "    ##############################\n",
    "    # Data preprocessing\n",
    "    # Extract necessary items\n",
    "    ##############################\n",
    "    # Load gender_submission.csv\n",
    "    df = pandas.read_csv('train.csv')\n",
    "    df_test = pandas.read_csv('test.csv')\n",
    "\n",
    "    df_all = pandas.concat([df, df_test], sort=False)\n",
    "\n",
    "    df_test_index = df_test[['PassengerId']]\n",
    "\n",
    "    df = df[['Survived', 'Pclass', 'Sex', 'SibSp', 'Parch','Ticket', 'Fare','Age','Name']]\n",
    "    df_test = df_test[['Pclass', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Fare','Age','Name']]\n",
    "\n",
    "    ##############################\n",
    "    # Data preprocessing\n",
    "    # Fill or remove missing values\n",
    "    ##############################\n",
    "    df = df[df['Fare'] != 5].reset_index(drop=True)\n",
    "    df = df[df['Fare'] != 0].reset_index(drop=True)\n",
    "\n",
    "    ##############################\n",
    "    # Data preprocessing\n",
    "    # Digitize labels\n",
    "    ##############################\n",
    "    # Gender\n",
    "    ##############################\n",
    "    encoder_sex = LabelEncoder()\n",
    "    df['Sex'] = encoder_sex.fit_transform(df['Sex'].values)\n",
    "    df_test['Sex'] = encoder_sex.transform(df_test['Sex'].values)\n",
    "    \n",
    "    \n",
    "    #Age\n",
    "    \n",
    "    df = df.fillna(df.mean()['Age'])\n",
    "    \n",
    "    df[\"Age_Category\"] = df[\"Age\"].apply(lambda x: 1 if (x >= 16) & (x < 32) \n",
    "                                     else 2 if (x >= 32) & (x < 48) \n",
    "                                     else 3 if (x >= 48) & (x < 64)\n",
    "                                     else 4 if (x >= 64)\n",
    "                                     else 0 if (x < 16)\n",
    "                                     else -1)\n",
    "    \n",
    "    df_test = df_test.fillna(df.mean()['Age'])\n",
    "    df_test[\"Age_Category\"] = df_test[\"Age\"].apply(lambda x: 1 if (x >= 16) & (x < 32) \n",
    "                                     else 2 if (x >= 32) & (x < 48) \n",
    "                                     else 3 if (x >= 48) & (x < 64)\n",
    "                                     else 4 if (x >= 64)\n",
    "                                     else 0 if (x < 16)\n",
    "                                     else -1)\n",
    "    \n",
    "    #title\n",
    "    \n",
    "    df['Title'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don',\\\n",
    "                                             'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'],\\\n",
    "                                             'Rare')\n",
    "    df['Title'] = df['Title'].replace('Mlle', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Ms', 'Miss')\n",
    "    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    _, df['Title'] = numpy.unique(df['Title'], return_inverse=True)\n",
    "    \n",
    "    df_test['Title'] = df_test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "\n",
    "    df_test['Title'] = df_test['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don',\\\n",
    "                                             'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'],\\\n",
    "                                             'Rare')\n",
    "    df_test['Title'] = df_test['Title'].replace('Mlle', 'Miss')\n",
    "    df_test['Title'] = df_test['Title'].replace('Ms', 'Miss')\n",
    "    df_test['Title'] = df_test['Title'].replace('Mme', 'Mrs')\n",
    "    \n",
    "    _, df_test['Title'] = numpy.unique(df_test['Title'], return_inverse=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ##############################\n",
    "    # Data preprocessing\n",
    "    # One-Hot Encoding\n",
    "    ##############################\n",
    "    ##############################\n",
    "    # SibSp\n",
    "    ##############################\n",
    "    df, df_test = get_dummies_sibSp(df_all, df, df_test)\n",
    "\n",
    "    ##############################\n",
    "    # Parch\n",
    "    ##############################\n",
    "    df, df_test = get_dummies_parch(df_all, df, df_test)\n",
    "\n",
    "    ##############################\n",
    "    # Ticket\n",
    "    ##############################\n",
    "#     df, df_test = get_dummies_ticket(df_all, df, df_test)\n",
    "\n",
    "    ##############################\n",
    "    ##############################\n",
    "    df, df_test = standardization(df, df_test)\n",
    "\n",
    "    ##############################\n",
    "    # Data preprocessing\n",
    "    # Fill or remove missing values\n",
    "    ##############################\n",
    "    df.fillna({'Fare':0}, inplace=True)\n",
    "    df_test.fillna({'Fare':0}, inplace=True)\n",
    "\n",
    "    ##############################\n",
    "    # Split training data and test data\n",
    "    ##############################\n",
    "    x_pre1 = df.drop(columns='Survived')\n",
    "#     x_pre2 = x_pre1.drop(columns = 'Age')\n",
    "    x_pre3 = x_pre2.drop(columns = 'Name')\n",
    "    x = x_pre3.drop(columns = 'Ticket')\n",
    "    y = df[['Survived']]\n",
    "    \n",
    "    df_test_pre1 = df_test.drop(columns='Age')\n",
    "    df_test_pre2 = df_test_pre1.drop(columns = 'Name')\n",
    "    df_test =df_test_pre2.drop(columns = 'Ticket')\n",
    "    \n",
    "    return x, y, df_test, df_test_index\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       Pclass  Sex      Fare  Age_Category  Title  SibSp_0  SibSp_1  SibSp_2  \\\n",
       " 0    0.818989    1 -0.511484             1      2        0        1        0   \n",
       " 1   -1.577718    0  0.771029             2      3        0        1        0   \n",
       " 2    0.818989    0 -0.497964             1      1        1        0        0   \n",
       " 3   -1.577718    0  0.406838             2      3        0        1        0   \n",
       " 4    0.818989    1 -0.495461             2      2        1        0        0   \n",
       " ..        ...  ...       ...           ...    ...      ...      ...      ...   \n",
       " 870 -0.379365    1 -0.396318             1      4        1        0        0   \n",
       " 871 -1.577718    0 -0.055828             1      1        1        0        0   \n",
       " 872  0.818989    0 -0.187017             1      1        0        1        0   \n",
       " 873 -1.577718    1 -0.055828             1      2        1        0        0   \n",
       " 874  0.818989    1 -0.501470             2      2        1        0        0   \n",
       " \n",
       "      SibSp_3  SibSp_4  SibSp_5  SibSp_8  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       " 0          0        0        0        0        1        0        0        0   \n",
       " 1          0        0        0        0        1        0        0        0   \n",
       " 2          0        0        0        0        1        0        0        0   \n",
       " 3          0        0        0        0        1        0        0        0   \n",
       " 4          0        0        0        0        1        0        0        0   \n",
       " ..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       " 870        0        0        0        0        1        0        0        0   \n",
       " 871        0        0        0        0        1        0        0        0   \n",
       " 872        0        0        0        0        0        0        1        0   \n",
       " 873        0        0        0        0        1        0        0        0   \n",
       " 874        0        0        0        0        1        0        0        0   \n",
       " \n",
       "      Parch_4  Parch_5  Parch_6  Parch_9  \n",
       " 0          0        0        0        0  \n",
       " 1          0        0        0        0  \n",
       " 2          0        0        0        0  \n",
       " 3          0        0        0        0  \n",
       " 4          0        0        0        0  \n",
       " ..       ...      ...      ...      ...  \n",
       " 870        0        0        0        0  \n",
       " 871        0        0        0        0  \n",
       " 872        0        0        0        0  \n",
       " 873        0        0        0        0  \n",
       " 874        0        0        0        0  \n",
       " \n",
       " [875 rows x 20 columns],\n",
       "      Survived\n",
       " 0           0\n",
       " 1           1\n",
       " 2           1\n",
       " 3           1\n",
       " 4           0\n",
       " ..        ...\n",
       " 870         0\n",
       " 871         1\n",
       " 872         0\n",
       " 873         1\n",
       " 874         0\n",
       " \n",
       " [875 rows x 1 columns],\n",
       "        Pclass  Sex      Fare  Age_Category  Title  SibSp_0  SibSp_1  SibSp_2  \\\n",
       " 0    0.818989    1 -0.499883             2      2        1        0        0   \n",
       " 1    0.818989    0 -0.516491             2      3        0        1        0   \n",
       " 2   -0.379365    1 -0.462664             3      2        1        0        0   \n",
       " 3    0.818989    1 -0.483193             1      2        1        0        0   \n",
       " 4    0.818989    0 -0.410589             1      3        0        1        0   \n",
       " ..        ...  ...       ...           ...    ...      ...      ...      ...   \n",
       " 413  0.818989    1 -0.495461             1      2        1        0        0   \n",
       " 414 -1.577718    0  1.524448             2      4        1        0        0   \n",
       " 415  0.818989    1 -0.511484             2      2        1        0        0   \n",
       " 416  0.818989    1 -0.495461             1      2        1        0        0   \n",
       " 417  0.818989    1 -0.208882             1      0        0        1        0   \n",
       " \n",
       "      SibSp_3  SibSp_4  SibSp_5  SibSp_8  Parch_0  Parch_1  Parch_2  Parch_3  \\\n",
       " 0          0        0        0        0        1        0        0        0   \n",
       " 1          0        0        0        0        1        0        0        0   \n",
       " 2          0        0        0        0        1        0        0        0   \n",
       " 3          0        0        0        0        1        0        0        0   \n",
       " 4          0        0        0        0        0        1        0        0   \n",
       " ..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       " 413        0        0        0        0        1        0        0        0   \n",
       " 414        0        0        0        0        1        0        0        0   \n",
       " 415        0        0        0        0        1        0        0        0   \n",
       " 416        0        0        0        0        1        0        0        0   \n",
       " 417        0        0        0        0        0        1        0        0   \n",
       " \n",
       "      Parch_4  Parch_5  Parch_6  Parch_9  \n",
       " 0          0        0        0        0  \n",
       " 1          0        0        0        0  \n",
       " 2          0        0        0        0  \n",
       " 3          0        0        0        0  \n",
       " 4          0        0        0        0  \n",
       " ..       ...      ...      ...      ...  \n",
       " 413        0        0        0        0  \n",
       " 414        0        0        0        0  \n",
       " 415        0        0        0        0  \n",
       " 416        0        0        0        0  \n",
       " 417        0        0        0        0  \n",
       " \n",
       " [418 rows x 20 columns],\n",
       "      PassengerId\n",
       " 0            892\n",
       " 1            893\n",
       " 2            894\n",
       " 3            895\n",
       " 4            896\n",
       " ..           ...\n",
       " 413         1305\n",
       " 414         1306\n",
       " 415         1307\n",
       " 416         1308\n",
       " 417         1309\n",
       " \n",
       " [418 rows x 1 columns])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepareData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "# Model -> 5perceptron\n",
    "##############################\n",
    "def create_model_5dim_layer_perceptron(input_dim, \\\n",
    "                                       activation=\"relu\", \\\n",
    "                                       optimizer=\"adam\", \\\n",
    "                                       out_dim=100, \\\n",
    "                                       dropout=0.5):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Input - Hidden1\n",
    "    model.add(Dense(input_dim=input_dim, units=out_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    # Hidden1 - Hidden2\n",
    "    model.add(Dense(units=out_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    # Hidden2 - Hidden3\n",
    "    model.add(Dense(units=out_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(activation))\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    # Hidden3 - Output\n",
    "    model.add(Dense(units=1))\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_49 (Dense)             (None, 702)               14742     \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 702)               2808      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 702)               0         \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 702)               0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 702)               493506    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 702)               2808      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 702)               0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 702)               0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 702)               493506    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 702)               2808      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 702)               0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 702)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 703       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,010,881\n",
      "Trainable params: 1,006,669\n",
      "Non-trainable params: 4,212\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test_index = prepareData()\n",
    "\n",
    "model = create_model_5dim_layer_perceptron(len(x_train.columns), \\\n",
    "                                           activation=\"relu\", \\\n",
    "                                           optimizer=\"adam\", \\\n",
    "                                           out_dim=702, \\\n",
    "                                           dropout=0.5)\n",
    "model.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      " - 1s - loss: 0.7022 - accuracy: 0.7006\n",
      "Epoch 2/25\n",
      " - 1s - loss: 0.6269 - accuracy: 0.7520\n",
      "Epoch 3/25\n",
      " - 1s - loss: 0.5734 - accuracy: 0.7726\n",
      "Epoch 4/25\n",
      " - 1s - loss: 0.5706 - accuracy: 0.7623\n",
      "Epoch 5/25\n",
      " - 1s - loss: 0.5186 - accuracy: 0.7783\n",
      "Epoch 6/25\n",
      " - 1s - loss: 0.5070 - accuracy: 0.7897\n",
      "Epoch 7/25\n",
      " - 1s - loss: 0.5050 - accuracy: 0.7931\n",
      "Epoch 8/25\n",
      " - 2s - loss: 0.4787 - accuracy: 0.7989\n",
      "Epoch 9/25\n",
      " - 1s - loss: 0.4865 - accuracy: 0.7977\n",
      "Epoch 10/25\n",
      " - 1s - loss: 0.4512 - accuracy: 0.8091\n",
      "Epoch 11/25\n",
      " - 1s - loss: 0.4688 - accuracy: 0.8000\n",
      "Epoch 12/25\n",
      " - 1s - loss: 0.4343 - accuracy: 0.8103\n",
      "Epoch 13/25\n",
      " - 2s - loss: 0.4378 - accuracy: 0.8171\n",
      "Epoch 14/25\n",
      " - 1s - loss: 0.4853 - accuracy: 0.8103\n",
      "Epoch 15/25\n",
      " - 1s - loss: 0.4600 - accuracy: 0.8183\n",
      "Epoch 16/25\n",
      " - 2s - loss: 0.4423 - accuracy: 0.8023\n",
      "Epoch 17/25\n",
      " - 1s - loss: 0.4353 - accuracy: 0.8171\n",
      "Epoch 18/25\n",
      " - 1s - loss: 0.4306 - accuracy: 0.8126\n",
      "Epoch 19/25\n",
      " - 1s - loss: 0.4322 - accuracy: 0.8080\n",
      "Epoch 20/25\n",
      " - 2s - loss: 0.4216 - accuracy: 0.8286\n",
      "Epoch 21/25\n",
      " - 2s - loss: 0.4487 - accuracy: 0.8126\n",
      "Epoch 22/25\n",
      " - 2s - loss: 0.4522 - accuracy: 0.8069\n",
      "Epoch 23/25\n",
      " - 1s - loss: 0.4281 - accuracy: 0.8160\n",
      "Epoch 24/25\n",
      " - 2s - loss: 0.4265 - accuracy: 0.8297\n",
      "Epoch 25/25\n",
      " - 1s - loss: 0.4455 - accuracy: 0.8103\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "fit = model.fit(x_train, y_train, epochs=25, batch_size=16, verbose=2)\n",
    "\n",
    "# Predict\n",
    "y_test_proba = model.predict(x_test)\n",
    "y_test = numpy.round(y_test_proba).astype(int)\n",
    "\n",
    "# Combine the data frame of PassengerId and the result\n",
    "df_output = pandas.concat([y_test_index, pandas.DataFrame(y_test, columns=['Survived'])], axis=1)\n",
    "\n",
    "# Write result.csv to the current directory\n",
    "df_output.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
